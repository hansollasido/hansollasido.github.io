---
title: "[Chap 1]"
excerpt: "한 번에 보는 머신러닝"

categories:
  - 핸즈온
tags:
  - [공부, 머신러닝]

permalink: /categories2/handson2/

toc: true
toc_sticky: true

date: 2023-01-30
last_modified_at: 2023-01-30
---

# 한눈에 보는 머신러닝

## 머신러닝이란?

일반적 정의 
- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야

공학적 정의
- 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것

---
**데이터 마이닝**
- 머신러닝 기술을 적용해서 대용량의 데이터를 분석하여 겉으로 보이지 않는 패턴을 발견할 수 있음

**지도 학습**
- 알고리즘에 주입하는 훈련 데이터에 **레이블**이라는 원하는 답이 포함된 학습
- 분류, 회귀
- 알고리즘
  - k-최근접 이웃
  - 선형 회귀
  - 로지스틱 회귀
  - 서포트 벡터 머신(SVM)
  - 결정 트리와 랜덤 포레스트
  - 신경망

**비지도 학습**
- 훈련 데이터에 레이블이 없음
- 알고리즘
  - 군집
    - k-평균
    - DBSCAN
    - 계층 군집 분석(HCA)
    - 이상치 탐지와 특이치 탐지
    - 원-클래스
    - 아이솔레이션 포레스트
  - 시각화와 차원 축소
    - 주성분 분석 (PCA)
    - 커널 PCA
    - 지역적 선형 임베딩(LLE)
    - t-SNE
  - 연관 규칙 학습
    - 어프라이어리
    - 이클렛

**차원 축소**
- 너무 많은 정보를 잃지 않으면서 데이터를 간소화함
- 두 특성을 하나의 특성으로 합칠 수 있음 : **특성 추출**

**이상치 탐지**
- 이상한 값을 자동으로 제거

**특이치 탐지**
- 훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지

**준지도 학습**
- 일부만 레이블이 있음
- 대부분 지도 학습과 비지도 학습의 조합으로 이루어져 있음
- **심층 신뢰 신경망**은 여러 겹으로 쌓은 **제한된 볼츠만 머신(RBM)**이라는 불리는 비지도 학습에 기초함

**강화 학습**
- 학습하는 시스템(에이전트)이 환경을 관찰해서 행동을 실행하고 그 결과로 **보상**을 받음
- 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책**이라 부르는 최상의 전략을 스스로 학습

**배치 학습**
- 시스템이 점진적으로 학습할 수 없음
- 학습한 것을 단지 적용만 함
- **오프라인 학습**이라고도 부름

**온라인 학습**
- 데이터를 순차적으로 한 개씩 또는 **미니배치**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킴
- 매 학습 단계가 빠르고 비용이 적게 들어 데이터가 도착하는 대로 즉시 학습함

**학습률**
- 변화하는 데이터에 얼마나 빠르게 적응할 것인지 나타냄
- 높으면 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림
- 낮게 하면 시스템의 관성이 더 커져 더 느리게 학습됨
  - 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐

---
머신러닝은 어떻게 **일반화**되는가에 따라 분류할 수 있음

---

**사례 기반 학습**
- 시스템이 훈련 샘플을 기억함으로써 학습하고 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화함

**모델 기반 학습**
- 샘플들의 모델을 만들어 **예측**에 사용함

<img src="../../assets/images/020801.png" width="300px" height="300px" title="OP code 예시" alt="OP code"><img><br/>

- 선형적으로 표현되어 있어 선형 모델로 모델 선택 가능
- $삶의 만족도 = \theta_0+\theta_1\times 1인당GDP$
  - theta_0과 theta_1인 두 개의 **모델 파라미터**를 가짐

**호용 함수 (또는 적합도 함수)**
- 모델이 얼마나 좋은지 측정

**비용 함수**
- 모델이 얼마나 나쁜지 측정

**훈련**
- 알고리즘에 훈련 데이터를 공급하면 데이터에 가장 잘 맞는 파라미터를 찾는 과정

---

## 도전과제

나쁜 알고리즘, 나쁜 데이터

<font color="blue">나쁜 데이터</font>
1. 충분하지 않는 훈련 데이터
2. 대표성이 없는 훈련 데이터
**샘플링 편향**
- 샘플이 작으면 **샘플링 잡음(우연에 의한 대표성 없는 데이터)**가 생김
- 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못함
3. 낮은 품질의 데이터
- 이상치, 잡음
4. 관련 없는 특성
- 특성 공학, 특성 선택을 사용하여 나쁜 데이터 제거

<font color="blue">나쁜 알고리즘</font>
1. 훈련 데이터 과대적합
- 과도하게 일반화하여 훈련 데이터에 너무 잘 맞아버림
- **규제**를 통해 모델에 제약을 가하고, **자유도**를 부여해 조절

<img src="../../assets/images/020802.png" width="300px" height="300px" title="OP code 예시" alt="OP code"><img><br/>

2. 훈련 데이터 과소적합
- 모델이 너무 단순해서 내재된 구조를 학습하지 못할 때 일어남

---

## 테스트와 검증

**훈련 세트**와 **테스트 세트**
- 훈련 데이터를 두 개로 나누어 훈련 세트로는 훈련, 테스트 세트로는 모델을 테스트함

**일반화 오차**
- 새로운 샘플에 대한 오류 비율
- 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻음

---
일반화 오차를 테스트 세트에서 여러 번 측정했기 때문에 테스트 세트에 최적화된 모델이 만들어짐
- 잘 동작하지 않을 수 있음

**홀드아웃 검증**
- 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택함
- 새로운 홀드 아웃 세트를 **검증 세트**라고 부름
- 검증 세트에서 가장 높은 성능을 내는 모델을 선택함

**교차 검증**
- 치중된 훈련 세트의 문제점을 해결하기 위해 작은 검증 세트를 여러 개 사용해 **교차 검증**을 수행함