---
title: "[ğŸ¤œì»´í“¨í„°êµ¬ì¡°ì„¤ê³„ ë° ì‘ìš© 10]"
excerpt: "Parallel PRocessors from Client to Cloud"

categories:
  - ì»´êµ¬ì„¤
tags:
  - [ìˆ˜ì—…]

permalink: /categories10/computer_architecture10/

use_math: true
toc: true
toc_sticky: true

date: 2023-06-04
last_modified_at: 2023-06-04
---

# ì»´í“¨í„°êµ¬ì¡°ì„¤ê³„ ë° ì‘ìš©

ìˆ˜ì—…ì„ ë“£ê³  ì •ë¦¬í•œ í˜ì´ì§€ ì…ë‹ˆë‹¤.

---

**Introduction**

- Goal: connecting multiple computers to get higher performance
  - Multiprocessors
  - Scalability, availability, power efficiency
- Task-level (process-level) parallelism
  - High throughput for independent jobs
- Parallel processing program
  - Single program run on multiple processors
- Multicore microprocessors
  - Chips with multiple processors (cores)

Multi processorëŠ” memory spaceê°€ ë…ë¦½ì ìœ¼ë¡œ ë‹¤ë¦„. Multi coreëŠ” memory space shareí•˜ê³  ì—°ì‚°ë§Œ ë”°ë¡œ 

---

**Hardware and Software**

- Hardware
  - Serial: e.g., Pentium 4
  - Parallel: e.g., quad-core Xeon e5345
- Software
  - Sequential: e.g., matrix multiplication
  - Concurrent: e.g., operating system
- Sequential/concurrent software can run on serial/parallel hardware
  - Challenge: making effective use of parallel hardware

ë§‰ìƒ softwareê°€ ë³‘ë ¬ì ìœ¼ë¡œ í•˜ëŠ” ê²ƒ ê°™ì§€ë§Œ ì‹¤ì œë¡œëŠ”  threadë¥¼ ë‚˜ëˆ ì„œ ë²ˆê°ˆì•„ ëŒì•„ê°€ëŠ” ì‘ì—…ì´ ë³‘ë ¬ì ìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒì„.


HWë„ ì¤‘ìš”í•˜ì§€ë§Œ ê·¸ ìì›ì„ ì‚¬ìš©í•˜ëŠ” SWë„ ì¤‘ìš”í•¨.

---

**Parallel Programming**

- Parallel software is the problem
- Need to get significant performance improvement
  - Otherwise, just use a faster uniprocessor, since it's easier.
- Difficulties
  - Partitioning
  - Coordination
  - Communications overhead

--- 

**Amdahl's Law**

- Sequential part can limit speedup
- Example: 100 processors, 90x speedup?
  - parallelí•œ ë¶€ë¶„ ë§ì•„ì•¼ speedup íš¨ìœ¨ì´ ì¢‹ì•„ì§

---

**Scaling Example**

- Workload: sum of 10 scalars, and 10 x 10 matrix sum
  - Speed up from 10 to 100 processors
- Single processor: Time = (10 + 100) x $t_{add}$
- 10 processors
  - Time = 10 x $t_{add}$ + 100/10 x $t_{add}$ = 20 x $t_{add}$
  - Speedup = 110/20 = 5.5 (55% of potential)
- 100 processors
  - Time = 10 x $t_{add}$ + 100/100 x $t_{add}$ = 11 x $t_{add}$
  - Speedup = 110/11 = 10 (10% of potential)
- Assumes load can be balanced across processors

---

**Scaling Example (cont)**

- What if matrix size is 100 x 100?
- Single processor: Time = (10 + 10000) x $t_{add}$
- 10 processors
  - Time = 10 x $t_{add}$ + 10000/10 x $t_{add}$ = 1010 x $t_{add}$
  - speedup = 10010/1010 = 9.9 (99% of potential)
- 100 processors
  - Time = 10 x $t_{add}$ + 10000/100 x $t_{add}$ = 110 x $t_{add}$
  - speedup = 10010/110 = 91 (91% of potential)
- Assuming load balanced

ìì›ì´ ë§ìœ¼ë©´ ë§ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ ì˜¬ë¼ê°€ê¸´ í•˜ì§€ë§Œ, linearí•˜ê²Œ ì˜¬ë¼ê°€ì§€ëŠ” ì•ŠìŒ

---

**Instruction and Data Streams**

- An alternate classification

<p align="center"><img src="../../assets/images/060601.jpg" width="500px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

- SPMD: Single Program Multiple Data
  - A parallel program on a MIMD computer
  - Conditional code for different processors

---

**SIMD**

- Operate elementwise on vecotrs of data
  - E.g., MMX and SSE instructions in x86
    - Multiple data elements in 128-bit wide registers
- All processors execute the same instruction at the same time
  - Each with different data address, etc.
- Simplifies synchronization
- Reduced instruction control hardware
- Works best for highly data-parallel applications

highly data-parallel applicationsì€ ë”¥ëŸ¬ë‹ ê°€ì†ê¸°ë¡œ ë§ì´ ì“°ì„

---

**Multithreading**

ì„¤ê³„, êµ¬ì¡°ì ì¸ ì–˜ê¸°ì„

- Performing multiple threads of execution in parallel
  - Replicate register, PC, etc.
  - Fast switching between threads
- Fine-grain multithreading (ì‘ì€ ë‹¨ìœ„)
  - Switch threads after each cycle
  - Interleave instruction execution
  - If one thread stalls, others are executed
- Coarse-grain multithreading (í° ë‹¨ìœ„)
  - Only switch on long stall (e.g., L2-cache miss)
  - Simplifies hardware, but doesn't hide short stalls (eg, data hazards)

---

**History of GPUs**

- Early video cards
  - Frame buffer memory with address generation for video output
- 3D graphics processing
  - Originally high-end computers (e.g., SGI)
  - Moore's Law => lower cost, higher density
  - 3D graphics cards for PCs and game concoles
- Graphics Processing Units
  - Processors oriented to 3D graphics tasks
  - Vertex/pixel processing, shading, texture mapping, rasterization

---

**GPU Architectures**

- Processing is highly data-parallel
  - GPUs are highly multithreaded
  - Use thread switching to hide memory latency
    - Less reliance on multi-level caches
  - Graphis memory is wide and high-bandwidth
- Trend toward general purpose GPUs
  - Heterogeneous CPU/GPU systems
  - CPU for sequential code, GPU for parallel code
- Programming languages/APIs
  - DirectX, OpenGL
  - C for Graphics (Cg), High Level Shader Language 9HLSL
  - Compute Unified Device Architecture (CUDA)

--- 

**Modeling Performance**

- Assume performance metric of interest is achievable GFLOPs/sec
  - Measured using computational kernels from Berkeley Design Patterns
- Arithmetic intensity of a kernel
  - FLOPs per byte of memory accessed
- For a given computer, determine
  - Peak  GFLOPS (from data sheet) 
  - Peak memory bytes/sec (using Stream benchmark)

FLOPs = Floating point operations

FLOPs/sec = FLOPS

FLOPSëŠ” ëŒ€í‘œì  GPU ì„±ëŠ¥ ìˆ˜ì¹˜ì„

---

**Roofline Diagram**

<p align="center"><img src="../../assets/images/060602.jpg" width="600px" height="600px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

HW ìµœê³  ì„±ëŠ¥ í•œê³„ë¡œ ì¸í•´ GFLOPs/secondê°€ ë†’ì§€ëŠ” ì•ŠìŒ

- ì–´ë–¤ ë¶€ë¶„ì—ì„œëŠ” Memory bandwidthë¡œ ì¸í•´, ì–´ë–¤ ë¶€ë¶„ì—ì„œëŠ” Processorë¡œ ì¸í•´ í•œê³„ê°€ ìˆìŒ

---

**Comparing Systems**

- Opteron X2, Opteron X4
  - 2-core vs. 4-core, 2x FP performance/core, 2.2GHz vs. 2.3GHz
  - Same memory system

<p align="center"><img src="../../assets/images/060603.jpg" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

- To get higher performance on X4 than X2
  - Need high arithmetic intensity
  - Or working set must fit in X4's 2MB L-3 cache

X4ì˜ ì„±ëŠ¥ì´ ì¢‹ê²Œ ë§Œë“¤ë ¤ë©´, ì—°ì‚° ê°•ë„ë¥¼ ë†’ì´ê±°ë‚˜ setê°€ X4ì˜ 2MB L-3 cacheì— ë§ìœ¼ë©´ ë¨

---

**Optimizing Performance**

<p align="center"><img src="../../assets/images/060604.jpg" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

- Optimize FP performance
  - Balance adds & multiplies
  - Improve superscalar ILP and use of SIMD instructions

<p align="center"><img src="../../assets/images/060605.jpg" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

- Optimize memory usage
  - Software prefetch
    - Avoid load stalls
  - Memory affinity (í”„ë¡œì„¸ìŠ¤ ë˜ëŠ” ìŠ¤ë ˆë“œê°€ ìš°ì„ ìˆœìœ„ ë˜ëŠ” ë°”ì¸ë”©ì„ ì§€ì •)
    - Avoid non-local data accesses

<p align="center"><img src="../../assets/images/060606.jpg" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

- Choice of optimization depends on arithmetic intensity of code
- Arithmetic intensity is not always fixed
  - May scale with problem size
  - Caching reduces memory accesses
    - Increases arithmetic intensity

Cachingì´ arithmetic intensityë¥¼ ì˜¬ë ¤ì¤Œ. arithmetic intensityëŠ” ê³ ì •ì ì´ì§€ ì•Šê¸° ë•Œë¬¸ì— ì–´ë–¤ íŠ¹ì„±ì¸ì§€ì— ë”°ë¼ ë‹¬ë¼ì§.

---

**Rooflines**

<p align="center"><img src="../../assets/images/060607.jpg" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>
  
---

**Concluding Remarks**

- Goal: higher performance by using multiple processors
- Difficulites
  - Developing parallel software
  - Devising appropriate architectrues
- SaaS importance is growing and clusters are a good match
- Performance per dollar and performance per Joule drive both mobile and WSC

SaaSëŠ” Software as a serviceì˜ ì•½ì. IaasëŠ” Infrastructure as a serviceì˜ ì•½ì. 

ì†ë„ ì˜¬ë¼ê°€ë©´ ì „ë ¥ì†Œëª¨ë„ ì˜¬ë¼ê°€ê¸° ë•Œë¬¸ì— overheadê°€ í¼. ì„±ëŠ¥ë‹¹ ë¹„ìš© ë° ì„±ëŠ¥ë‹¹ ì—ë„ˆì§€ ì†Œëª¨ ë˜í•œ ë§¤ìš° ì¤‘ìš”í•¨. 

---

## í€´ì¦ˆ

**1) íŠ¹ì • SWì½”ë“œì˜ ì„œë¡œ ë‹¤ë¥¸ ë‘ lineì€ ë³‘ë ¬ HW ì—†ì´ëŠ” ë™ì‹œì— ì‹¤í–‰ë  ìˆ˜ ì—†ë‹¤.** <font color="red">Y</font>

**2-1) 8ë°°ì˜ speedupì„ ì–»ìœ¼ë ¤ë©´ ëª‡ ê°œì˜ processorê°€ í•„ìš”í•œê°€?**

<font color="red">(10 + 100)t / (10 + 100/x)t = 8 -> x>27</font>

**ê·¸ë¦¬ê³  ì´ ë•ŒëŠ” potential ëŒ€ë¹„ ëª‡ % ì„±ëŠ¥ í–¥ìƒì¸ê°€?**

<font color="red">8.x/27 = ì•½ 30%</font>

**2-2) ì´ ê²½ìš°ì—ì„œ ì´ë¡ ì ìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ìµœëŒ€ speedupì€ ëª‡ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ”ê°€?**

<font color="red">processor ê°œìˆ˜ê°€ 100ê°œ ì´ˆê³¼í•˜ë©´ ì‹¤ì§ˆì ì¸ ì†ë„ í–¥ìƒì´ ì—†ìœ¼ë¯€ë¡œ (10+100)/(10+1) = 10ë°°</font>

**3) roofline diagramì—ì„œ,** 

**3-1) Kernel 1ì— ëŒ€í•´ 2ë°°ì˜ ì„±ëŠ¥í–¥ìƒì„ ì–»ê¸° ìœ„í•œ ë°©ë²•?**
  - <font color="red">Arithmetic intensity 2ë°° ì¦ê°€ ë˜ëŠ”</font>
  - <font color="red">Peak memory BW 2ë°° ì¦ê°€</font>

**3-2) Kernel 2ì— ëŒ€í•´ 2ë°°ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì–»ê¸° ìœ„í•œ ë°©ë²•?**
  - <font color="red">Peak floating-point performance 2ë°° ì¦ê°€</font>

**3-3) Rooflineê³¼ x,y ì¶•ì´ ì´ë£¨ëŠ” ì˜ì—­ì˜ ë„“ì´ê°€ ë„“ì„ìˆ˜ë¡ ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ì€ ì‹œìŠ¤í…œì´ë¼ê³  í•  ìˆ˜ ìˆëŠ”ê°€?**
  - <font color="red">ì¼ë°˜ì ìœ¼ë¡œ yes</font>

**4) ì•„ë˜ì˜ í‘œëŠ” NVIDIA A100ê³¼ H100 GPUì— ëŒ€í•œ ì—°ì‚°/ë©”ëª¨ë¦¬ ì„±ëŠ¥ ìˆ˜ì¹˜ ì¤‘ ì¼ë¶€ì´ë‹¤.** 

<p align="center"><img src="../../assets/images/060608.png" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

**4-1) ê° GPUì˜ ì„±ëŠ¥ (FP16, INT8 ê²½ìš° ëª¨ë‘, with sparsity ê°€ì •)ì„ roofline diagramìœ¼ë¡œ ë‚˜íƒ€ë‚´ì‹œì˜¤.**

<p align="center"><img src="../../assets/images/060609.png" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>

**4-2) Arithmetic intensityê°€ 600 OPS/Byteì¼ ë•Œ ë‘ GPUì˜ ì„±ëŠ¥ ì°¨ì´ëŠ”?**

- <font color="red">A100-FP16:624, INT8:1200</font>
- <font color="red">H100-FP16:1979, INT8:2010</font>

**4-3) H100 GPUë¡œ 3000 TFLOPSë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ë°©ë²•ì€?**

- <font color="red">INT8 ì´ìš©, Arithmetic intensity=(3000/3.35)Ops/B ì´ìƒìœ¼ë¡œ ë™ì‘

**4-4) H100 GPUì˜ memory BWê°€ 1TB/së¡œ ì¤„ì–´ë“¤ì—ˆë‹¤ê³  í•  ë•Œ, H100 ì´ A100ë³´ë‹¤ ì„±ëŠ¥ì´ ë” ì¢‹ê¸° ìœ„í•œ arithmetic intensityì˜ ë²”ìœ„ëŠ”?**

<p align="center"><img src="../../assets/images/060610.png" width="400px" height="400px" title="OP code ì˜ˆì‹œ" alt="OP code" ><img></p>